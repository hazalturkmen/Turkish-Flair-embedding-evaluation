{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair turkish ner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZfYbfgH7X7Q",
        "outputId": "84eea7fb-a259-44bf-e0fc-7ae775c844f2"
      },
      "source": [
        "!pip install flair\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/a0/a1b41fa2fcb23ff71ba9148af75211dcccc35b256dea821b36e1ee871848/flair-0.7-py3-none-any.whl (448kB)\n",
            "\r\u001b[K     |▊                               | 10kB 29.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 33.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 18.1MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 15.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 44.3MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 82.8MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/01/47358efec5396fc80f98273c42cbdfe7aab056252b07884ffcc0f118978f/konoha-4.6.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 49.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece<=0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.7.0+cu101)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Collecting transformers<=3.5.1,>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (4.0.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.3.2->flair) (2.23.0)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.17.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (20.7)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (2020.12.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->flair) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<=3.5.1,>=3.5.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: mpld3, ftfy, langdetect, sqlitedict, segtok, overrides, sacremoses\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=7eb7b417eba4ee4b7223fa970623b0c01d4a400f9a4faa47318209fa8a25e593\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45613 sha256=9c6c823ba5275c4719a6b5643fb63f1bca3af939ffb0dc59641176e54be08394\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=4903e25ff02f37aa200cd3ff59f55fe88cfa7a780aa163d9a7c32332898f34c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp36-none-any.whl size=14377 sha256=3b07896741b9823c68a8994adb7d74841b3106b43a33d1ed163cb78c01cc4a91\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=3c23d71c33ce050cc6519fc1985187c54853f92b192ae907b0678171abce722f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=d400e19bec6c032f05973da93c2361966d7c28746ca7f6b0f16e3833a4206920\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=b8c733a0ff49738dba8261dcb40dfc245ff4dfbc109a32c4701fc6147fd9690f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built mpld3 ftfy langdetect sqlitedict segtok overrides sacremoses\n",
            "Installing collected packages: mpld3, janome, sentencepiece, bpemb, overrides, konoha, ftfy, langdetect, sqlitedict, deprecated, segtok, sacremoses, tokenizers, transformers, flair\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.10 flair-0.7 ftfy-5.8 janome-0.4.1 konoha-4.6.2 langdetect-1.0.8 mpld3-0.3 overrides-3.0.0 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.7.0 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCQVivaVwigV",
        "outputId": "6490b6a9-2dc7-4764-ab1c-e5846ac020f6"
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "# Make a sentence object by passing an untokenized string and the 'use_tokenizer' flag\n",
        "sentence = Sentence('The grass is green.', use_tokenizer=True)\n",
        "\n",
        "# Print the object to see what's in there\n",
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"The grass is green .\"   [− Tokens: 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX0EgHVoz6Md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3191062a-12d5-4203-b500-865905a79f27"
      },
      "source": [
        "for token in sentence:\n",
        "    print(token)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token: 1 The\n",
            "Token: 2 grass\n",
            "Token: 3 is\n",
            "Token: 4 green\n",
            "Token: 5 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBPxy-lg7pJq",
        "outputId": "80381205-0c38-45a5-8c24-85c7f8a38426"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ht1LqD9qGl"
      },
      "source": [
        "from flair.datasets import ColumnCorpus\n",
        "from flair.data import Corpus\n",
        "from flair.embeddings import WordEmbeddings, BytePairEmbeddings, StackedEmbeddings, CharacterEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from flair.data import Sentence\n",
        "from flair.embeddings import StackedEmbeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-eapXXu8cU_"
      },
      "source": [
        "def corpus_loader(data_path):\n",
        "  columns = {0: 'text', 1: 'ner'}\n",
        "  corpus: Corpus = ColumnCorpus(data_path, columns, train_file='outBIOtrain-conll.txt', test_file='outBIOtest-conll.txt')\n",
        "  \n",
        "  return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgbxJ5St-kOc"
      },
      "source": [
        "def get_embedding(param):\n",
        "  embedding_types = [ WordEmbeddings('/content/drive/MyDrive/wvec models/wvec_model.wv'),\n",
        "  CharacterEmbeddings(),\n",
        "  WordEmbeddings('tr'),\n",
        "  TransformerWordEmbeddings('dbmdz/bert-base-turkish-cased', layers='-1')]\n",
        "  if (param=='w2vec'):    \n",
        "    return embedding_types[0]\n",
        "  elif (param=='char'):    \n",
        "    return embedding_types[1]\n",
        "  elif (param=='fsttx'):   \n",
        "    return embedding_types[2]\n",
        "  elif (param=='transformer'):    \n",
        "    return embedding_types[3]\n",
        "  elif (param=='w2vec+char'):\n",
        "    return StackedEmbeddings([embedding_types[0],embedding_types[1]])\n",
        "  elif (param=='fsttx+char'):\n",
        "    return StackedEmbeddings([embedding_types[2],embedding_types[1]])\n",
        "  elif (param=='w2vec+transformer'):\n",
        "    return StackedEmbeddings([embedding_types[0],embedding_types[3]])\n",
        "  elif (param=='fsttx+transformer'):\n",
        "    return StackedEmbeddings([embedding_types[2],embedding_types[3]])\n",
        "  elif (param=='w2vec+char+transformer'):\n",
        "    return StackedEmbeddings([embedding_types[0],embedding_types[1],embedding_types[3]])\n",
        "  elif (param=='fsttx+char+transformer'):\n",
        "    return StackedEmbeddings([embedding_types[2],embedding_types[1],embedding_types[3]])        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZvHMc8sV14G"
      },
      "source": [
        "def main():\n",
        "  corpus = corpus_loader(\"/content/drive/MyDrive/ner_data\")\n",
        "  tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
        "  embedding = get_embedding('fsttx+char+transformer')\n",
        "  tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                       embeddings=embedding,\n",
        "                                       tag_dictionary=tag_dictionary,\n",
        "                                       tag_type='ner',\n",
        "                                       use_crf=True)\n",
        "  trainer : ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "  trainer.train('resources/taggers/example-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEcg3R94XX49",
        "outputId": "11810bf5-36f5-49aa-ae87-016b9592d173"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 19:25:32,896 Reading data from /content/drive/MyDrive/ner_data\n",
            "2020-12-06 19:25:32,898 Train: /content/drive/MyDrive/ner_data/outBIOtrain-conll.txt\n",
            "2020-12-06 19:25:32,899 Dev: None\n",
            "2020-12-06 19:25:32,900 Test: /content/drive/MyDrive/ner_data/outBIOtest-conll.txt\n",
            "2020-12-06 19:26:32,827 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:26:32,830 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('tr')\n",
            "    (list_embedding_1): CharacterEmbeddings(\n",
            "      (char_embedding): Embedding(275, 25)\n",
            "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
            "    )\n",
            "    (list_embedding_2): TransformerWordEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=1118, out_features=1118, bias=True)\n",
            "  (rnn): LSTM(1118, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-12-06 19:26:32,831 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:26:32,836 Corpus: \"Corpus: 22326 train + 2481 dev + 2757 test sentences\"\n",
            "2020-12-06 19:26:32,840 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:26:32,842 Parameters:\n",
            "2020-12-06 19:26:32,843  - learning_rate: \"0.1\"\n",
            "2020-12-06 19:26:32,844  - mini_batch_size: \"32\"\n",
            "2020-12-06 19:26:32,846  - patience: \"3\"\n",
            "2020-12-06 19:26:32,849  - anneal_factor: \"0.5\"\n",
            "2020-12-06 19:26:32,852  - max_epochs: \"50\"\n",
            "2020-12-06 19:26:32,855  - shuffle: \"True\"\n",
            "2020-12-06 19:26:32,856  - train_with_dev: \"False\"\n",
            "2020-12-06 19:26:32,857  - batch_growth_annealing: \"False\"\n",
            "2020-12-06 19:26:32,858 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:26:32,861 Model training base path: \"resources/taggers/example-ner\"\n",
            "2020-12-06 19:26:32,862 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:26:32,863 Device: cuda:0\n",
            "2020-12-06 19:26:32,864 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:26:32,866 Embeddings storage mode: cpu\n",
            "2020-12-06 19:26:32,875 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:27:48,897 epoch 1 - iter 69/698 - loss 8.95945945 - samples/sec: 29.05 - lr: 0.100000\n",
            "2020-12-06 19:29:06,363 epoch 1 - iter 138/698 - loss 6.57479160 - samples/sec: 28.51 - lr: 0.100000\n",
            "2020-12-06 19:30:21,707 epoch 1 - iter 207/698 - loss 5.25171640 - samples/sec: 29.31 - lr: 0.100000\n",
            "2020-12-06 19:31:39,824 epoch 1 - iter 276/698 - loss 4.50645716 - samples/sec: 28.27 - lr: 0.100000\n",
            "2020-12-06 19:32:59,063 epoch 1 - iter 345/698 - loss 4.06531439 - samples/sec: 27.87 - lr: 0.100000\n",
            "2020-12-06 19:34:20,591 epoch 1 - iter 414/698 - loss 3.67632272 - samples/sec: 27.09 - lr: 0.100000\n",
            "2020-12-06 19:35:37,700 epoch 1 - iter 483/698 - loss 3.37686930 - samples/sec: 28.64 - lr: 0.100000\n",
            "2020-12-06 19:36:55,181 epoch 1 - iter 552/698 - loss 3.14844722 - samples/sec: 28.50 - lr: 0.100000\n",
            "2020-12-06 19:38:13,055 epoch 1 - iter 621/698 - loss 2.96895589 - samples/sec: 28.36 - lr: 0.100000\n",
            "2020-12-06 19:39:30,184 epoch 1 - iter 690/698 - loss 2.81033885 - samples/sec: 28.63 - lr: 0.100000\n",
            "2020-12-06 19:39:38,681 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:39:38,682 EPOCH 1 done: loss 2.7927 - lr 0.1000000\n",
            "2020-12-06 19:40:36,507 DEV : loss 1.4452306032180786 - score 0.8574\n",
            "2020-12-06 19:40:36,699 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 19:40:44,196 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:41:25,694 epoch 2 - iter 69/698 - loss 1.24573138 - samples/sec: 53.25 - lr: 0.100000\n",
            "2020-12-06 19:42:05,124 epoch 2 - iter 138/698 - loss 1.25192869 - samples/sec: 56.01 - lr: 0.100000\n",
            "2020-12-06 19:42:44,800 epoch 2 - iter 207/698 - loss 1.19693301 - samples/sec: 55.66 - lr: 0.100000\n",
            "2020-12-06 19:43:26,984 epoch 2 - iter 276/698 - loss 1.19789432 - samples/sec: 52.35 - lr: 0.100000\n",
            "2020-12-06 19:44:08,034 epoch 2 - iter 345/698 - loss 1.18223841 - samples/sec: 53.80 - lr: 0.100000\n",
            "2020-12-06 19:44:52,550 epoch 2 - iter 414/698 - loss 1.25199305 - samples/sec: 49.61 - lr: 0.100000\n",
            "2020-12-06 19:45:35,238 epoch 2 - iter 483/698 - loss 1.24458675 - samples/sec: 51.73 - lr: 0.100000\n",
            "2020-12-06 19:46:13,682 epoch 2 - iter 552/698 - loss 1.22315685 - samples/sec: 57.44 - lr: 0.100000\n",
            "2020-12-06 19:46:53,888 epoch 2 - iter 621/698 - loss 1.19685996 - samples/sec: 54.93 - lr: 0.100000\n",
            "2020-12-06 19:47:35,560 epoch 2 - iter 690/698 - loss 1.18545403 - samples/sec: 52.99 - lr: 0.100000\n",
            "2020-12-06 19:47:40,209 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:47:40,210 EPOCH 2 done: loss 1.1820 - lr 0.1000000\n",
            "2020-12-06 19:47:57,300 DEV : loss 1.3654956817626953 - score 0.8813\n",
            "2020-12-06 19:47:57,496 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 19:48:04,818 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:48:47,251 epoch 3 - iter 69/698 - loss 1.03040067 - samples/sec: 52.08 - lr: 0.100000\n",
            "2020-12-06 19:49:28,567 epoch 3 - iter 138/698 - loss 0.99694182 - samples/sec: 53.45 - lr: 0.100000\n",
            "2020-12-06 19:50:07,568 epoch 3 - iter 207/698 - loss 0.97014148 - samples/sec: 56.62 - lr: 0.100000\n",
            "2020-12-06 19:50:49,421 epoch 3 - iter 276/698 - loss 1.00277044 - samples/sec: 52.77 - lr: 0.100000\n",
            "2020-12-06 19:51:30,078 epoch 3 - iter 345/698 - loss 0.97563772 - samples/sec: 54.32 - lr: 0.100000\n",
            "2020-12-06 19:52:12,064 epoch 3 - iter 414/698 - loss 0.97459127 - samples/sec: 52.60 - lr: 0.100000\n",
            "2020-12-06 19:52:50,213 epoch 3 - iter 483/698 - loss 0.94911335 - samples/sec: 57.89 - lr: 0.100000\n",
            "2020-12-06 19:53:29,732 epoch 3 - iter 552/698 - loss 0.93926618 - samples/sec: 55.88 - lr: 0.100000\n",
            "2020-12-06 19:54:10,332 epoch 3 - iter 621/698 - loss 0.93723787 - samples/sec: 54.39 - lr: 0.100000\n",
            "2020-12-06 19:54:55,258 epoch 3 - iter 690/698 - loss 0.96214869 - samples/sec: 49.16 - lr: 0.100000\n",
            "2020-12-06 19:54:59,601 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:54:59,602 EPOCH 3 done: loss 0.9628 - lr 0.1000000\n",
            "2020-12-06 19:55:16,716 DEV : loss 1.0649278163909912 - score 0.894\n",
            "2020-12-06 19:55:16,914 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 19:55:24,177 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 19:56:07,179 epoch 4 - iter 69/698 - loss 0.81496299 - samples/sec: 51.37 - lr: 0.100000\n",
            "2020-12-06 19:56:47,572 epoch 4 - iter 138/698 - loss 0.82812424 - samples/sec: 54.67 - lr: 0.100000\n",
            "2020-12-06 19:57:30,525 epoch 4 - iter 207/698 - loss 0.85120475 - samples/sec: 51.41 - lr: 0.100000\n",
            "2020-12-06 19:58:10,133 epoch 4 - iter 276/698 - loss 0.83666050 - samples/sec: 55.76 - lr: 0.100000\n",
            "2020-12-06 19:58:49,402 epoch 4 - iter 345/698 - loss 0.83486362 - samples/sec: 56.24 - lr: 0.100000\n",
            "2020-12-06 19:59:28,951 epoch 4 - iter 414/698 - loss 0.83407191 - samples/sec: 55.84 - lr: 0.100000\n",
            "2020-12-06 20:00:10,409 epoch 4 - iter 483/698 - loss 0.87208426 - samples/sec: 53.27 - lr: 0.100000\n",
            "2020-12-06 20:00:51,726 epoch 4 - iter 552/698 - loss 0.87308231 - samples/sec: 53.45 - lr: 0.100000\n",
            "2020-12-06 20:01:30,660 epoch 4 - iter 621/698 - loss 0.86511201 - samples/sec: 56.72 - lr: 0.100000\n",
            "2020-12-06 20:02:13,501 epoch 4 - iter 690/698 - loss 0.86937339 - samples/sec: 51.55 - lr: 0.100000\n",
            "2020-12-06 20:02:17,918 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:02:17,920 EPOCH 4 done: loss 0.8681 - lr 0.1000000\n",
            "2020-12-06 20:02:35,336 DEV : loss 1.1227262020111084 - score 0.8923\n",
            "2020-12-06 20:02:35,525 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 20:02:35,528 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:03:19,251 epoch 5 - iter 69/698 - loss 0.73652954 - samples/sec: 50.51 - lr: 0.100000\n",
            "2020-12-06 20:04:00,379 epoch 5 - iter 138/698 - loss 0.82573807 - samples/sec: 53.69 - lr: 0.100000\n",
            "2020-12-06 20:04:41,746 epoch 5 - iter 207/698 - loss 0.81169599 - samples/sec: 53.39 - lr: 0.100000\n",
            "2020-12-06 20:05:21,030 epoch 5 - iter 276/698 - loss 0.79744268 - samples/sec: 56.22 - lr: 0.100000\n",
            "2020-12-06 20:06:04,284 epoch 5 - iter 345/698 - loss 0.81791225 - samples/sec: 51.06 - lr: 0.100000\n",
            "2020-12-06 20:06:43,367 epoch 5 - iter 414/698 - loss 0.79348650 - samples/sec: 56.51 - lr: 0.100000\n",
            "2020-12-06 20:07:23,296 epoch 5 - iter 483/698 - loss 0.79131440 - samples/sec: 55.31 - lr: 0.100000\n",
            "2020-12-06 20:08:03,945 epoch 5 - iter 552/698 - loss 0.78743366 - samples/sec: 54.33 - lr: 0.100000\n",
            "2020-12-06 20:08:42,116 epoch 5 - iter 621/698 - loss 0.77754795 - samples/sec: 57.86 - lr: 0.100000\n",
            "2020-12-06 20:09:24,447 epoch 5 - iter 690/698 - loss 0.80331797 - samples/sec: 52.17 - lr: 0.100000\n",
            "2020-12-06 20:09:29,280 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:09:29,283 EPOCH 5 done: loss 0.8032 - lr 0.1000000\n",
            "2020-12-06 20:09:46,263 DEV : loss 1.0366790294647217 - score 0.8917\n",
            "2020-12-06 20:09:46,453 BAD EPOCHS (no improvement): 2\n",
            "2020-12-06 20:09:46,454 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:10:26,502 epoch 6 - iter 69/698 - loss 0.75876053 - samples/sec: 55.15 - lr: 0.100000\n",
            "2020-12-06 20:11:07,379 epoch 6 - iter 138/698 - loss 0.70203447 - samples/sec: 54.02 - lr: 0.100000\n",
            "2020-12-06 20:11:46,978 epoch 6 - iter 207/698 - loss 0.72352938 - samples/sec: 55.77 - lr: 0.100000\n",
            "2020-12-06 20:12:28,776 epoch 6 - iter 276/698 - loss 0.73505907 - samples/sec: 52.83 - lr: 0.100000\n",
            "2020-12-06 20:13:09,183 epoch 6 - iter 345/698 - loss 0.73291860 - samples/sec: 54.65 - lr: 0.100000\n",
            "2020-12-06 20:13:49,990 epoch 6 - iter 414/698 - loss 0.72552087 - samples/sec: 54.12 - lr: 0.100000\n",
            "2020-12-06 20:14:32,231 epoch 6 - iter 483/698 - loss 0.75510215 - samples/sec: 52.28 - lr: 0.100000\n",
            "2020-12-06 20:15:13,421 epoch 6 - iter 552/698 - loss 0.74423792 - samples/sec: 53.62 - lr: 0.100000\n",
            "2020-12-06 20:15:54,038 epoch 6 - iter 621/698 - loss 0.74287397 - samples/sec: 54.37 - lr: 0.100000\n",
            "2020-12-06 20:16:33,712 epoch 6 - iter 690/698 - loss 0.73702239 - samples/sec: 55.66 - lr: 0.100000\n",
            "2020-12-06 20:16:37,870 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:16:37,873 EPOCH 6 done: loss 0.7370 - lr 0.1000000\n",
            "2020-12-06 20:16:54,816 DEV : loss 1.0026237964630127 - score 0.8956\n",
            "2020-12-06 20:16:55,015 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 20:17:02,401 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:17:44,037 epoch 7 - iter 69/698 - loss 0.65201521 - samples/sec: 53.06 - lr: 0.100000\n",
            "2020-12-06 20:18:24,926 epoch 7 - iter 138/698 - loss 0.65061002 - samples/sec: 54.01 - lr: 0.100000\n",
            "2020-12-06 20:19:05,606 epoch 7 - iter 207/698 - loss 0.68817004 - samples/sec: 54.29 - lr: 0.100000\n",
            "2020-12-06 20:19:48,502 epoch 7 - iter 276/698 - loss 0.71273436 - samples/sec: 51.48 - lr: 0.100000\n",
            "2020-12-06 20:20:29,834 epoch 7 - iter 345/698 - loss 0.71164972 - samples/sec: 53.43 - lr: 0.100000\n",
            "2020-12-06 20:21:09,433 epoch 7 - iter 414/698 - loss 0.70877619 - samples/sec: 55.77 - lr: 0.100000\n",
            "2020-12-06 20:21:51,701 epoch 7 - iter 483/698 - loss 0.72832171 - samples/sec: 52.25 - lr: 0.100000\n",
            "2020-12-06 20:22:31,271 epoch 7 - iter 552/698 - loss 0.71033621 - samples/sec: 55.81 - lr: 0.100000\n",
            "2020-12-06 20:23:10,383 epoch 7 - iter 621/698 - loss 0.70883319 - samples/sec: 56.46 - lr: 0.100000\n",
            "2020-12-06 20:23:52,849 epoch 7 - iter 690/698 - loss 0.71059218 - samples/sec: 52.00 - lr: 0.100000\n",
            "2020-12-06 20:23:57,666 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:23:57,667 EPOCH 7 done: loss 0.7146 - lr 0.1000000\n",
            "2020-12-06 20:24:16,030 DEV : loss 0.9756280183792114 - score 0.8965\n",
            "2020-12-06 20:24:16,226 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 20:24:23,329 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:25:02,836 epoch 8 - iter 69/698 - loss 0.67343905 - samples/sec: 55.90 - lr: 0.100000\n",
            "2020-12-06 20:25:43,218 epoch 8 - iter 138/698 - loss 0.65789413 - samples/sec: 54.69 - lr: 0.100000\n",
            "2020-12-06 20:26:22,962 epoch 8 - iter 207/698 - loss 0.62496584 - samples/sec: 55.57 - lr: 0.100000\n",
            "2020-12-06 20:27:02,645 epoch 8 - iter 276/698 - loss 0.61544082 - samples/sec: 55.65 - lr: 0.100000\n",
            "2020-12-06 20:27:45,058 epoch 8 - iter 345/698 - loss 0.67259911 - samples/sec: 52.07 - lr: 0.100000\n",
            "2020-12-06 20:28:25,458 epoch 8 - iter 414/698 - loss 0.67642885 - samples/sec: 54.66 - lr: 0.100000\n",
            "2020-12-06 20:29:06,789 epoch 8 - iter 483/698 - loss 0.68161042 - samples/sec: 53.43 - lr: 0.100000\n",
            "2020-12-06 20:29:47,218 epoch 8 - iter 552/698 - loss 0.68685398 - samples/sec: 54.62 - lr: 0.100000\n",
            "2020-12-06 20:30:29,753 epoch 8 - iter 621/698 - loss 0.68737144 - samples/sec: 51.92 - lr: 0.100000\n",
            "2020-12-06 20:31:09,107 epoch 8 - iter 690/698 - loss 0.68466992 - samples/sec: 56.11 - lr: 0.100000\n",
            "2020-12-06 20:31:14,390 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:31:14,392 EPOCH 8 done: loss 0.6869 - lr 0.1000000\n",
            "2020-12-06 20:31:31,595 DEV : loss 0.9350784420967102 - score 0.9005\n",
            "2020-12-06 20:31:31,820 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 20:31:39,028 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:32:18,946 epoch 9 - iter 69/698 - loss 0.55775287 - samples/sec: 55.34 - lr: 0.100000\n",
            "2020-12-06 20:32:59,333 epoch 9 - iter 138/698 - loss 0.58574355 - samples/sec: 54.68 - lr: 0.100000\n",
            "2020-12-06 20:33:40,179 epoch 9 - iter 207/698 - loss 0.58983859 - samples/sec: 54.07 - lr: 0.100000\n",
            "2020-12-06 20:34:24,734 epoch 9 - iter 276/698 - loss 0.66002475 - samples/sec: 49.57 - lr: 0.100000\n",
            "2020-12-06 20:35:03,567 epoch 9 - iter 345/698 - loss 0.64483139 - samples/sec: 56.87 - lr: 0.100000\n",
            "2020-12-06 20:35:45,826 epoch 9 - iter 414/698 - loss 0.65650165 - samples/sec: 52.26 - lr: 0.100000\n",
            "2020-12-06 20:36:25,566 epoch 9 - iter 483/698 - loss 0.65365978 - samples/sec: 55.57 - lr: 0.100000\n",
            "2020-12-06 20:37:06,919 epoch 9 - iter 552/698 - loss 0.64813761 - samples/sec: 53.40 - lr: 0.100000\n",
            "2020-12-06 20:37:51,264 epoch 9 - iter 621/698 - loss 0.66223031 - samples/sec: 49.80 - lr: 0.100000\n",
            "2020-12-06 20:38:32,812 epoch 9 - iter 690/698 - loss 0.66459267 - samples/sec: 53.15 - lr: 0.100000\n",
            "2020-12-06 20:38:37,024 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:38:37,025 EPOCH 9 done: loss 0.6642 - lr 0.1000000\n",
            "2020-12-06 20:38:53,991 DEV : loss 0.8863878846168518 - score 0.906\n",
            "2020-12-06 20:38:54,182 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 20:39:01,321 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:39:43,726 epoch 10 - iter 69/698 - loss 0.79134741 - samples/sec: 52.11 - lr: 0.100000\n",
            "2020-12-06 20:40:25,156 epoch 10 - iter 138/698 - loss 0.72392619 - samples/sec: 53.31 - lr: 0.100000\n",
            "2020-12-06 20:41:08,319 epoch 10 - iter 207/698 - loss 0.69458840 - samples/sec: 51.16 - lr: 0.100000\n",
            "2020-12-06 20:41:47,715 epoch 10 - iter 276/698 - loss 0.66250821 - samples/sec: 56.06 - lr: 0.100000\n",
            "2020-12-06 20:42:27,252 epoch 10 - iter 345/698 - loss 0.64314370 - samples/sec: 55.86 - lr: 0.100000\n",
            "2020-12-06 20:43:09,845 epoch 10 - iter 414/698 - loss 0.63362036 - samples/sec: 51.85 - lr: 0.100000\n",
            "2020-12-06 20:43:49,640 epoch 10 - iter 483/698 - loss 0.63551299 - samples/sec: 55.50 - lr: 0.100000\n",
            "2020-12-06 20:44:32,366 epoch 10 - iter 552/698 - loss 0.64690546 - samples/sec: 51.69 - lr: 0.100000\n",
            "2020-12-06 20:45:12,102 epoch 10 - iter 621/698 - loss 0.64151835 - samples/sec: 55.58 - lr: 0.100000\n",
            "2020-12-06 20:45:53,902 epoch 10 - iter 690/698 - loss 0.64215973 - samples/sec: 52.83 - lr: 0.100000\n",
            "2020-12-06 20:45:58,126 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:45:58,128 EPOCH 10 done: loss 0.6429 - lr 0.1000000\n",
            "2020-12-06 20:46:16,449 DEV : loss 0.8830819129943848 - score 0.9054\n",
            "2020-12-06 20:46:16,638 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 20:46:16,640 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:46:58,446 epoch 11 - iter 69/698 - loss 0.55353114 - samples/sec: 52.83 - lr: 0.100000\n",
            "2020-12-06 20:47:40,464 epoch 11 - iter 138/698 - loss 0.60890625 - samples/sec: 52.56 - lr: 0.100000\n",
            "2020-12-06 20:48:21,811 epoch 11 - iter 207/698 - loss 0.60295502 - samples/sec: 53.41 - lr: 0.100000\n",
            "2020-12-06 20:49:00,910 epoch 11 - iter 276/698 - loss 0.60537777 - samples/sec: 56.49 - lr: 0.100000\n",
            "2020-12-06 20:49:40,126 epoch 11 - iter 345/698 - loss 0.58851929 - samples/sec: 56.32 - lr: 0.100000\n",
            "2020-12-06 20:50:22,695 epoch 11 - iter 414/698 - loss 0.62191052 - samples/sec: 51.88 - lr: 0.100000\n",
            "2020-12-06 20:51:04,772 epoch 11 - iter 483/698 - loss 0.62017473 - samples/sec: 52.48 - lr: 0.100000\n",
            "2020-12-06 20:51:45,555 epoch 11 - iter 552/698 - loss 0.61358679 - samples/sec: 54.15 - lr: 0.100000\n",
            "2020-12-06 20:52:26,501 epoch 11 - iter 621/698 - loss 0.60767929 - samples/sec: 53.93 - lr: 0.100000\n",
            "2020-12-06 20:53:09,998 epoch 11 - iter 690/698 - loss 0.62087737 - samples/sec: 50.77 - lr: 0.100000\n",
            "2020-12-06 20:53:14,213 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:53:14,214 EPOCH 11 done: loss 0.6218 - lr 0.1000000\n",
            "2020-12-06 20:53:31,286 DEV : loss 0.840040922164917 - score 0.9092\n",
            "2020-12-06 20:53:31,485 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 20:53:38,810 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 20:54:19,072 epoch 12 - iter 69/698 - loss 0.55283086 - samples/sec: 54.85 - lr: 0.100000\n",
            "2020-12-06 20:55:02,063 epoch 12 - iter 138/698 - loss 0.58098586 - samples/sec: 51.37 - lr: 0.100000\n",
            "2020-12-06 20:55:40,093 epoch 12 - iter 207/698 - loss 0.58786954 - samples/sec: 58.07 - lr: 0.100000\n",
            "2020-12-06 20:56:20,495 epoch 12 - iter 276/698 - loss 0.58146006 - samples/sec: 54.66 - lr: 0.100000\n",
            "2020-12-06 20:57:04,221 epoch 12 - iter 345/698 - loss 0.61389659 - samples/sec: 50.50 - lr: 0.100000\n",
            "2020-12-06 20:57:45,056 epoch 12 - iter 414/698 - loss 0.62216311 - samples/sec: 54.08 - lr: 0.100000\n",
            "2020-12-06 20:58:29,849 epoch 12 - iter 483/698 - loss 0.63624712 - samples/sec: 49.30 - lr: 0.100000\n",
            "2020-12-06 20:59:10,131 epoch 12 - iter 552/698 - loss 0.62341387 - samples/sec: 54.83 - lr: 0.100000\n",
            "2020-12-06 20:59:51,243 epoch 12 - iter 621/698 - loss 0.61705500 - samples/sec: 53.72 - lr: 0.100000\n",
            "2020-12-06 21:00:30,655 epoch 12 - iter 690/698 - loss 0.60984698 - samples/sec: 56.04 - lr: 0.100000\n",
            "2020-12-06 21:00:34,743 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:00:34,744 EPOCH 12 done: loss 0.6082 - lr 0.1000000\n",
            "2020-12-06 21:00:51,776 DEV : loss 0.9002040028572083 - score 0.9092\n",
            "2020-12-06 21:00:51,981 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 21:00:51,993 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:01:31,863 epoch 13 - iter 69/698 - loss 0.60655790 - samples/sec: 55.39 - lr: 0.100000\n",
            "2020-12-06 21:02:13,210 epoch 13 - iter 138/698 - loss 0.59139788 - samples/sec: 53.41 - lr: 0.100000\n",
            "2020-12-06 21:02:52,782 epoch 13 - iter 207/698 - loss 0.59048736 - samples/sec: 55.81 - lr: 0.100000\n",
            "2020-12-06 21:03:35,888 epoch 13 - iter 276/698 - loss 0.57550860 - samples/sec: 51.23 - lr: 0.100000\n",
            "2020-12-06 21:04:15,726 epoch 13 - iter 345/698 - loss 0.58734865 - samples/sec: 55.43 - lr: 0.100000\n",
            "2020-12-06 21:04:59,586 epoch 13 - iter 414/698 - loss 0.60799704 - samples/sec: 50.35 - lr: 0.100000\n",
            "2020-12-06 21:05:40,366 epoch 13 - iter 483/698 - loss 0.60488108 - samples/sec: 54.15 - lr: 0.100000\n",
            "2020-12-06 21:06:21,188 epoch 13 - iter 552/698 - loss 0.60250879 - samples/sec: 54.10 - lr: 0.100000\n",
            "2020-12-06 21:07:00,888 epoch 13 - iter 621/698 - loss 0.59861310 - samples/sec: 55.63 - lr: 0.100000\n",
            "2020-12-06 21:07:42,410 epoch 13 - iter 690/698 - loss 0.59394330 - samples/sec: 53.19 - lr: 0.100000\n",
            "2020-12-06 21:07:46,888 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:07:46,891 EPOCH 13 done: loss 0.5929 - lr 0.1000000\n",
            "2020-12-06 21:08:05,589 DEV : loss 0.9167869091033936 - score 0.9103\n",
            "2020-12-06 21:08:05,780 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 21:08:13,031 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:08:56,576 epoch 14 - iter 69/698 - loss 0.52568427 - samples/sec: 50.72 - lr: 0.100000\n",
            "2020-12-06 21:09:36,812 epoch 14 - iter 138/698 - loss 0.52538765 - samples/sec: 54.89 - lr: 0.100000\n",
            "2020-12-06 21:10:16,085 epoch 14 - iter 207/698 - loss 0.53135318 - samples/sec: 56.23 - lr: 0.100000\n",
            "2020-12-06 21:10:57,298 epoch 14 - iter 276/698 - loss 0.53899159 - samples/sec: 53.58 - lr: 0.100000\n",
            "2020-12-06 21:11:43,695 epoch 14 - iter 345/698 - loss 0.59750187 - samples/sec: 47.60 - lr: 0.100000\n",
            "2020-12-06 21:12:23,909 epoch 14 - iter 414/698 - loss 0.59242814 - samples/sec: 54.92 - lr: 0.100000\n",
            "2020-12-06 21:13:05,085 epoch 14 - iter 483/698 - loss 0.59569377 - samples/sec: 53.63 - lr: 0.100000\n",
            "2020-12-06 21:13:44,829 epoch 14 - iter 552/698 - loss 0.58681056 - samples/sec: 55.56 - lr: 0.100000\n",
            "2020-12-06 21:14:24,290 epoch 14 - iter 621/698 - loss 0.58320450 - samples/sec: 55.96 - lr: 0.100000\n",
            "2020-12-06 21:15:02,392 epoch 14 - iter 690/698 - loss 0.57874260 - samples/sec: 57.96 - lr: 0.100000\n",
            "2020-12-06 21:15:06,485 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:15:06,486 EPOCH 14 done: loss 0.5783 - lr 0.1000000\n",
            "2020-12-06 21:15:23,710 DEV : loss 0.8964688181877136 - score 0.9119\n",
            "2020-12-06 21:15:23,902 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 21:15:31,093 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:16:11,256 epoch 15 - iter 69/698 - loss 0.50015015 - samples/sec: 55.00 - lr: 0.100000\n",
            "2020-12-06 21:16:51,761 epoch 15 - iter 138/698 - loss 0.49919750 - samples/sec: 54.52 - lr: 0.100000\n",
            "2020-12-06 21:17:31,624 epoch 15 - iter 207/698 - loss 0.50201631 - samples/sec: 55.40 - lr: 0.100000\n",
            "2020-12-06 21:18:11,274 epoch 15 - iter 276/698 - loss 0.51050855 - samples/sec: 55.70 - lr: 0.100000\n",
            "2020-12-06 21:18:52,267 epoch 15 - iter 345/698 - loss 0.50553207 - samples/sec: 53.87 - lr: 0.100000\n",
            "2020-12-06 21:19:32,637 epoch 15 - iter 414/698 - loss 0.52195089 - samples/sec: 54.70 - lr: 0.100000\n",
            "2020-12-06 21:20:13,667 epoch 15 - iter 483/698 - loss 0.53534220 - samples/sec: 53.82 - lr: 0.100000\n",
            "2020-12-06 21:20:53,779 epoch 15 - iter 552/698 - loss 0.53606676 - samples/sec: 55.06 - lr: 0.100000\n",
            "2020-12-06 21:21:36,147 epoch 15 - iter 621/698 - loss 0.56593159 - samples/sec: 52.12 - lr: 0.100000\n",
            "2020-12-06 21:22:18,481 epoch 15 - iter 690/698 - loss 0.57598519 - samples/sec: 52.17 - lr: 0.100000\n",
            "2020-12-06 21:22:23,696 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:22:23,699 EPOCH 15 done: loss 0.5760 - lr 0.1000000\n",
            "2020-12-06 21:22:40,180 DEV : loss 0.8705599904060364 - score 0.911\n",
            "2020-12-06 21:22:40,375 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 21:22:40,377 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:23:19,122 epoch 16 - iter 69/698 - loss 0.52520937 - samples/sec: 57.00 - lr: 0.100000\n",
            "2020-12-06 21:24:01,531 epoch 16 - iter 138/698 - loss 0.54076197 - samples/sec: 52.08 - lr: 0.100000\n",
            "2020-12-06 21:24:41,561 epoch 16 - iter 207/698 - loss 0.55278338 - samples/sec: 55.17 - lr: 0.100000\n",
            "2020-12-06 21:25:21,002 epoch 16 - iter 276/698 - loss 0.55094767 - samples/sec: 55.99 - lr: 0.100000\n",
            "2020-12-06 21:26:01,949 epoch 16 - iter 345/698 - loss 0.53224958 - samples/sec: 53.93 - lr: 0.100000\n",
            "2020-12-06 21:26:42,537 epoch 16 - iter 414/698 - loss 0.56468864 - samples/sec: 54.41 - lr: 0.100000\n",
            "2020-12-06 21:27:24,044 epoch 16 - iter 483/698 - loss 0.55348590 - samples/sec: 53.21 - lr: 0.100000\n",
            "2020-12-06 21:28:04,010 epoch 16 - iter 552/698 - loss 0.54578902 - samples/sec: 55.26 - lr: 0.100000\n",
            "2020-12-06 21:28:44,019 epoch 16 - iter 621/698 - loss 0.54939384 - samples/sec: 55.20 - lr: 0.100000\n",
            "2020-12-06 21:29:25,647 epoch 16 - iter 690/698 - loss 0.55229425 - samples/sec: 53.05 - lr: 0.100000\n",
            "2020-12-06 21:29:30,254 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:29:30,255 EPOCH 16 done: loss 0.5522 - lr 0.1000000\n",
            "2020-12-06 21:29:48,997 DEV : loss 0.8338451981544495 - score 0.9086\n",
            "2020-12-06 21:29:49,190 BAD EPOCHS (no improvement): 2\n",
            "2020-12-06 21:29:49,192 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:30:29,912 epoch 17 - iter 69/698 - loss 0.52975837 - samples/sec: 54.24 - lr: 0.100000\n",
            "2020-12-06 21:31:10,591 epoch 17 - iter 138/698 - loss 0.56520435 - samples/sec: 54.29 - lr: 0.100000\n",
            "2020-12-06 21:31:48,648 epoch 17 - iter 207/698 - loss 0.52684525 - samples/sec: 58.03 - lr: 0.100000\n",
            "2020-12-06 21:32:31,747 epoch 17 - iter 276/698 - loss 0.53559692 - samples/sec: 51.24 - lr: 0.100000\n",
            "2020-12-06 21:33:10,703 epoch 17 - iter 345/698 - loss 0.52789663 - samples/sec: 56.69 - lr: 0.100000\n",
            "2020-12-06 21:33:50,356 epoch 17 - iter 414/698 - loss 0.51962431 - samples/sec: 55.69 - lr: 0.100000\n",
            "2020-12-06 21:34:35,906 epoch 17 - iter 483/698 - loss 0.55676159 - samples/sec: 48.48 - lr: 0.100000\n",
            "2020-12-06 21:35:14,226 epoch 17 - iter 552/698 - loss 0.54231551 - samples/sec: 57.63 - lr: 0.100000\n",
            "2020-12-06 21:35:56,311 epoch 17 - iter 621/698 - loss 0.53800324 - samples/sec: 52.47 - lr: 0.100000\n",
            "2020-12-06 21:36:34,506 epoch 17 - iter 690/698 - loss 0.53836146 - samples/sec: 57.82 - lr: 0.100000\n",
            "2020-12-06 21:36:40,030 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:36:40,031 EPOCH 17 done: loss 0.5399 - lr 0.1000000\n",
            "2020-12-06 21:36:56,575 DEV : loss 0.8604481220245361 - score 0.9116\n",
            "2020-12-06 21:36:56,770 BAD EPOCHS (no improvement): 3\n",
            "2020-12-06 21:36:56,771 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:37:39,564 epoch 18 - iter 69/698 - loss 0.58186695 - samples/sec: 51.61 - lr: 0.100000\n",
            "2020-12-06 21:38:21,481 epoch 18 - iter 138/698 - loss 0.56872118 - samples/sec: 52.68 - lr: 0.100000\n",
            "2020-12-06 21:39:01,314 epoch 18 - iter 207/698 - loss 0.55484084 - samples/sec: 55.44 - lr: 0.100000\n",
            "2020-12-06 21:39:39,837 epoch 18 - iter 276/698 - loss 0.53973510 - samples/sec: 57.33 - lr: 0.100000\n",
            "2020-12-06 21:40:19,217 epoch 18 - iter 345/698 - loss 0.53203061 - samples/sec: 56.08 - lr: 0.100000\n",
            "2020-12-06 21:40:58,868 epoch 18 - iter 414/698 - loss 0.51740710 - samples/sec: 55.69 - lr: 0.100000\n",
            "2020-12-06 21:41:38,868 epoch 18 - iter 483/698 - loss 0.52120337 - samples/sec: 55.21 - lr: 0.100000\n",
            "2020-12-06 21:42:18,027 epoch 18 - iter 552/698 - loss 0.51705852 - samples/sec: 56.40 - lr: 0.100000\n",
            "2020-12-06 21:42:58,887 epoch 18 - iter 621/698 - loss 0.51960192 - samples/sec: 54.05 - lr: 0.100000\n",
            "2020-12-06 21:43:42,051 epoch 18 - iter 690/698 - loss 0.54355152 - samples/sec: 51.16 - lr: 0.100000\n",
            "2020-12-06 21:43:46,293 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:43:46,294 EPOCH 18 done: loss 0.5437 - lr 0.1000000\n",
            "2020-12-06 21:44:02,981 DEV : loss 0.8304586410522461 - score 0.9128\n",
            "2020-12-06 21:44:03,174 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 21:44:10,367 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:44:55,889 epoch 19 - iter 69/698 - loss 0.75301244 - samples/sec: 48.52 - lr: 0.100000\n",
            "2020-12-06 21:45:34,594 epoch 19 - iter 138/698 - loss 0.61335678 - samples/sec: 57.06 - lr: 0.100000\n",
            "2020-12-06 21:46:12,727 epoch 19 - iter 207/698 - loss 0.55088572 - samples/sec: 57.91 - lr: 0.100000\n",
            "2020-12-06 21:46:53,021 epoch 19 - iter 276/698 - loss 0.54792160 - samples/sec: 54.81 - lr: 0.100000\n",
            "2020-12-06 21:47:32,950 epoch 19 - iter 345/698 - loss 0.54321599 - samples/sec: 55.31 - lr: 0.100000\n",
            "2020-12-06 21:48:11,863 epoch 19 - iter 414/698 - loss 0.53234630 - samples/sec: 56.75 - lr: 0.100000\n",
            "2020-12-06 21:48:54,266 epoch 19 - iter 483/698 - loss 0.53196811 - samples/sec: 52.08 - lr: 0.100000\n",
            "2020-12-06 21:49:36,287 epoch 19 - iter 552/698 - loss 0.52556377 - samples/sec: 52.56 - lr: 0.100000\n",
            "2020-12-06 21:50:18,964 epoch 19 - iter 621/698 - loss 0.51890130 - samples/sec: 51.75 - lr: 0.100000\n",
            "2020-12-06 21:51:00,799 epoch 19 - iter 690/698 - loss 0.52788400 - samples/sec: 52.79 - lr: 0.100000\n",
            "2020-12-06 21:51:05,238 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:51:05,239 EPOCH 19 done: loss 0.5255 - lr 0.1000000\n",
            "2020-12-06 21:51:23,629 DEV : loss 0.8536989092826843 - score 0.9141\n",
            "2020-12-06 21:51:23,819 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 21:51:30,962 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:52:08,218 epoch 20 - iter 69/698 - loss 0.41250435 - samples/sec: 59.29 - lr: 0.100000\n",
            "2020-12-06 21:52:47,350 epoch 20 - iter 138/698 - loss 0.43648346 - samples/sec: 56.44 - lr: 0.100000\n",
            "2020-12-06 21:53:29,214 epoch 20 - iter 207/698 - loss 0.52494164 - samples/sec: 52.75 - lr: 0.100000\n",
            "2020-12-06 21:54:10,519 epoch 20 - iter 276/698 - loss 0.51902796 - samples/sec: 53.46 - lr: 0.100000\n",
            "2020-12-06 21:54:52,497 epoch 20 - iter 345/698 - loss 0.50742214 - samples/sec: 52.61 - lr: 0.100000\n",
            "2020-12-06 21:55:32,372 epoch 20 - iter 414/698 - loss 0.50330845 - samples/sec: 55.38 - lr: 0.100000\n",
            "2020-12-06 21:56:12,168 epoch 20 - iter 483/698 - loss 0.50149792 - samples/sec: 55.49 - lr: 0.100000\n",
            "2020-12-06 21:56:52,377 epoch 20 - iter 552/698 - loss 0.50033469 - samples/sec: 54.93 - lr: 0.100000\n",
            "2020-12-06 21:57:33,732 epoch 20 - iter 621/698 - loss 0.49923407 - samples/sec: 53.40 - lr: 0.100000\n",
            "2020-12-06 21:58:18,223 epoch 20 - iter 690/698 - loss 0.51458153 - samples/sec: 49.64 - lr: 0.100000\n",
            "2020-12-06 21:58:22,097 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:58:22,098 EPOCH 20 done: loss 0.5139 - lr 0.1000000\n",
            "2020-12-06 21:58:38,710 DEV : loss 0.8233761787414551 - score 0.9158\n",
            "2020-12-06 21:58:38,902 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 21:58:46,093 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 21:59:23,991 epoch 21 - iter 69/698 - loss 0.46630461 - samples/sec: 58.28 - lr: 0.100000\n",
            "2020-12-06 22:00:05,207 epoch 21 - iter 138/698 - loss 0.48998435 - samples/sec: 53.58 - lr: 0.100000\n",
            "2020-12-06 22:00:42,887 epoch 21 - iter 207/698 - loss 0.47822421 - samples/sec: 58.61 - lr: 0.100000\n",
            "2020-12-06 22:01:25,967 epoch 21 - iter 276/698 - loss 0.54585896 - samples/sec: 51.26 - lr: 0.100000\n",
            "2020-12-06 22:02:06,453 epoch 21 - iter 345/698 - loss 0.54090180 - samples/sec: 54.55 - lr: 0.100000\n",
            "2020-12-06 22:02:47,196 epoch 21 - iter 414/698 - loss 0.53097091 - samples/sec: 54.20 - lr: 0.100000\n",
            "2020-12-06 22:03:28,779 epoch 21 - iter 483/698 - loss 0.52467468 - samples/sec: 53.11 - lr: 0.100000\n",
            "2020-12-06 22:04:07,908 epoch 21 - iter 552/698 - loss 0.51979271 - samples/sec: 56.44 - lr: 0.100000\n",
            "2020-12-06 22:04:47,691 epoch 21 - iter 621/698 - loss 0.51412829 - samples/sec: 55.51 - lr: 0.100000\n",
            "2020-12-06 22:05:27,612 epoch 21 - iter 690/698 - loss 0.51508635 - samples/sec: 55.32 - lr: 0.100000\n",
            "2020-12-06 22:05:32,293 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:05:32,293 EPOCH 21 done: loss 0.5147 - lr 0.1000000\n",
            "2020-12-06 22:05:48,843 DEV : loss 0.7802987694740295 - score 0.9151\n",
            "2020-12-06 22:05:49,035 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 22:05:49,039 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:06:30,932 epoch 22 - iter 69/698 - loss 0.68125900 - samples/sec: 52.72 - lr: 0.100000\n",
            "2020-12-06 22:07:09,321 epoch 22 - iter 138/698 - loss 0.55873385 - samples/sec: 57.53 - lr: 0.100000\n",
            "2020-12-06 22:07:48,452 epoch 22 - iter 207/698 - loss 0.53662658 - samples/sec: 56.43 - lr: 0.100000\n",
            "2020-12-06 22:08:29,247 epoch 22 - iter 276/698 - loss 0.52164950 - samples/sec: 54.13 - lr: 0.100000\n",
            "2020-12-06 22:09:08,955 epoch 22 - iter 345/698 - loss 0.51247615 - samples/sec: 55.61 - lr: 0.100000\n",
            "2020-12-06 22:09:50,486 epoch 22 - iter 414/698 - loss 0.51242311 - samples/sec: 53.17 - lr: 0.100000\n",
            "2020-12-06 22:10:34,559 epoch 22 - iter 483/698 - loss 0.50859230 - samples/sec: 50.11 - lr: 0.100000\n",
            "2020-12-06 22:11:16,095 epoch 22 - iter 552/698 - loss 0.50610844 - samples/sec: 53.17 - lr: 0.100000\n",
            "2020-12-06 22:11:56,114 epoch 22 - iter 621/698 - loss 0.50711202 - samples/sec: 55.18 - lr: 0.100000\n",
            "2020-12-06 22:12:38,399 epoch 22 - iter 690/698 - loss 0.50796453 - samples/sec: 52.23 - lr: 0.100000\n",
            "2020-12-06 22:12:42,629 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:12:42,630 EPOCH 22 done: loss 0.5071 - lr 0.1000000\n",
            "2020-12-06 22:12:59,443 DEV : loss 0.781636655330658 - score 0.915\n",
            "2020-12-06 22:12:59,670 BAD EPOCHS (no improvement): 2\n",
            "2020-12-06 22:12:59,672 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:13:41,095 epoch 23 - iter 69/698 - loss 0.47399406 - samples/sec: 53.32 - lr: 0.100000\n",
            "2020-12-06 22:14:18,560 epoch 23 - iter 138/698 - loss 0.47553467 - samples/sec: 58.95 - lr: 0.100000\n",
            "2020-12-06 22:14:58,510 epoch 23 - iter 207/698 - loss 0.47128972 - samples/sec: 55.28 - lr: 0.100000\n",
            "2020-12-06 22:15:40,620 epoch 23 - iter 276/698 - loss 0.47210867 - samples/sec: 52.44 - lr: 0.100000\n",
            "2020-12-06 22:16:19,487 epoch 23 - iter 345/698 - loss 0.47409787 - samples/sec: 56.82 - lr: 0.100000\n",
            "2020-12-06 22:17:03,078 epoch 23 - iter 414/698 - loss 0.47872482 - samples/sec: 50.66 - lr: 0.100000\n",
            "2020-12-06 22:17:45,591 epoch 23 - iter 483/698 - loss 0.50588801 - samples/sec: 51.94 - lr: 0.100000\n",
            "2020-12-06 22:18:24,432 epoch 23 - iter 552/698 - loss 0.49817472 - samples/sec: 56.86 - lr: 0.100000\n",
            "2020-12-06 22:19:05,087 epoch 23 - iter 621/698 - loss 0.49442382 - samples/sec: 54.32 - lr: 0.100000\n",
            "2020-12-06 22:19:44,514 epoch 23 - iter 690/698 - loss 0.49237887 - samples/sec: 56.01 - lr: 0.100000\n",
            "2020-12-06 22:19:49,011 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:19:49,013 EPOCH 23 done: loss 0.4933 - lr 0.1000000\n",
            "2020-12-06 22:20:05,777 DEV : loss 0.8017856478691101 - score 0.918\n",
            "2020-12-06 22:20:05,967 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 22:20:13,104 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:20:56,300 epoch 24 - iter 69/698 - loss 0.59439774 - samples/sec: 51.14 - lr: 0.100000\n",
            "2020-12-06 22:21:37,543 epoch 24 - iter 138/698 - loss 0.53133250 - samples/sec: 53.55 - lr: 0.100000\n",
            "2020-12-06 22:22:15,002 epoch 24 - iter 207/698 - loss 0.49803259 - samples/sec: 58.95 - lr: 0.100000\n",
            "2020-12-06 22:22:59,081 epoch 24 - iter 276/698 - loss 0.53982360 - samples/sec: 50.10 - lr: 0.100000\n",
            "2020-12-06 22:23:41,066 epoch 24 - iter 345/698 - loss 0.52796866 - samples/sec: 52.60 - lr: 0.100000\n",
            "2020-12-06 22:24:19,723 epoch 24 - iter 414/698 - loss 0.51873220 - samples/sec: 57.13 - lr: 0.100000\n",
            "2020-12-06 22:24:59,944 epoch 24 - iter 483/698 - loss 0.50968154 - samples/sec: 54.91 - lr: 0.100000\n",
            "2020-12-06 22:25:41,153 epoch 24 - iter 552/698 - loss 0.51096904 - samples/sec: 53.59 - lr: 0.100000\n",
            "2020-12-06 22:26:22,860 epoch 24 - iter 621/698 - loss 0.50676191 - samples/sec: 52.95 - lr: 0.100000\n",
            "2020-12-06 22:27:02,716 epoch 24 - iter 690/698 - loss 0.49796118 - samples/sec: 55.41 - lr: 0.100000\n",
            "2020-12-06 22:27:07,620 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:27:07,622 EPOCH 24 done: loss 0.4986 - lr 0.1000000\n",
            "2020-12-06 22:27:24,396 DEV : loss 0.8591410517692566 - score 0.9146\n",
            "2020-12-06 22:27:24,587 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 22:27:24,591 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:28:04,627 epoch 25 - iter 69/698 - loss 0.47108177 - samples/sec: 55.16 - lr: 0.100000\n",
            "2020-12-06 22:28:46,379 epoch 25 - iter 138/698 - loss 0.45623476 - samples/sec: 52.89 - lr: 0.100000\n",
            "2020-12-06 22:29:24,459 epoch 25 - iter 207/698 - loss 0.47053612 - samples/sec: 57.99 - lr: 0.100000\n",
            "2020-12-06 22:30:03,837 epoch 25 - iter 276/698 - loss 0.47138091 - samples/sec: 56.08 - lr: 0.100000\n",
            "2020-12-06 22:30:46,472 epoch 25 - iter 345/698 - loss 0.49642562 - samples/sec: 51.80 - lr: 0.100000\n",
            "2020-12-06 22:31:27,048 epoch 25 - iter 414/698 - loss 0.49535955 - samples/sec: 54.43 - lr: 0.100000\n",
            "2020-12-06 22:32:09,586 epoch 25 - iter 483/698 - loss 0.49717439 - samples/sec: 51.92 - lr: 0.100000\n",
            "2020-12-06 22:32:50,367 epoch 25 - iter 552/698 - loss 0.49581384 - samples/sec: 54.15 - lr: 0.100000\n",
            "2020-12-06 22:33:31,447 epoch 25 - iter 621/698 - loss 0.48840827 - samples/sec: 53.76 - lr: 0.100000\n",
            "2020-12-06 22:34:11,816 epoch 25 - iter 690/698 - loss 0.49170642 - samples/sec: 54.71 - lr: 0.100000\n",
            "2020-12-06 22:34:16,304 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:34:16,305 EPOCH 25 done: loss 0.4905 - lr 0.1000000\n",
            "2020-12-06 22:34:33,263 DEV : loss 0.890485942363739 - score 0.916\n",
            "2020-12-06 22:34:33,459 BAD EPOCHS (no improvement): 2\n",
            "2020-12-06 22:34:33,460 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:35:14,287 epoch 26 - iter 69/698 - loss 0.42623071 - samples/sec: 54.09 - lr: 0.100000\n",
            "2020-12-06 22:35:57,102 epoch 26 - iter 138/698 - loss 0.55263217 - samples/sec: 51.58 - lr: 0.100000\n",
            "2020-12-06 22:36:37,228 epoch 26 - iter 207/698 - loss 0.52182946 - samples/sec: 55.04 - lr: 0.100000\n",
            "2020-12-06 22:37:15,859 epoch 26 - iter 276/698 - loss 0.49945556 - samples/sec: 57.17 - lr: 0.100000\n",
            "2020-12-06 22:37:57,246 epoch 26 - iter 345/698 - loss 0.49544256 - samples/sec: 53.36 - lr: 0.100000\n",
            "2020-12-06 22:38:38,110 epoch 26 - iter 414/698 - loss 0.48045482 - samples/sec: 54.04 - lr: 0.100000\n",
            "2020-12-06 22:39:18,824 epoch 26 - iter 483/698 - loss 0.47679463 - samples/sec: 54.24 - lr: 0.100000\n",
            "2020-12-06 22:40:00,502 epoch 26 - iter 552/698 - loss 0.47461953 - samples/sec: 52.99 - lr: 0.100000\n",
            "2020-12-06 22:40:40,282 epoch 26 - iter 621/698 - loss 0.47387312 - samples/sec: 55.52 - lr: 0.100000\n",
            "2020-12-06 22:41:19,179 epoch 26 - iter 690/698 - loss 0.47049232 - samples/sec: 56.78 - lr: 0.100000\n",
            "2020-12-06 22:41:25,010 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:41:25,011 EPOCH 26 done: loss 0.4741 - lr 0.1000000\n",
            "2020-12-06 22:41:41,706 DEV : loss 0.799572765827179 - score 0.9165\n",
            "2020-12-06 22:41:41,900 BAD EPOCHS (no improvement): 3\n",
            "2020-12-06 22:41:41,903 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:42:20,058 epoch 27 - iter 69/698 - loss 0.43487282 - samples/sec: 57.88 - lr: 0.100000\n",
            "2020-12-06 22:43:03,292 epoch 27 - iter 138/698 - loss 0.49218866 - samples/sec: 51.08 - lr: 0.100000\n",
            "2020-12-06 22:43:43,652 epoch 27 - iter 207/698 - loss 0.48279956 - samples/sec: 54.72 - lr: 0.100000\n",
            "2020-12-06 22:44:21,499 epoch 27 - iter 276/698 - loss 0.47864350 - samples/sec: 58.35 - lr: 0.100000\n",
            "2020-12-06 22:45:02,791 epoch 27 - iter 345/698 - loss 0.47625979 - samples/sec: 53.48 - lr: 0.100000\n",
            "2020-12-06 22:45:44,083 epoch 27 - iter 414/698 - loss 0.47653002 - samples/sec: 53.49 - lr: 0.100000\n",
            "2020-12-06 22:46:23,458 epoch 27 - iter 483/698 - loss 0.46745490 - samples/sec: 56.09 - lr: 0.100000\n",
            "2020-12-06 22:47:06,311 epoch 27 - iter 552/698 - loss 0.46323158 - samples/sec: 51.53 - lr: 0.100000\n",
            "2020-12-06 22:47:47,020 epoch 27 - iter 621/698 - loss 0.46307968 - samples/sec: 54.25 - lr: 0.100000\n",
            "2020-12-06 22:48:27,715 epoch 27 - iter 690/698 - loss 0.46880658 - samples/sec: 54.27 - lr: 0.100000\n",
            "2020-12-06 22:48:32,790 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:48:32,793 EPOCH 27 done: loss 0.4675 - lr 0.1000000\n",
            "2020-12-06 22:48:49,788 DEV : loss 0.8336436748504639 - score 0.9179\n",
            "Epoch    27: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-12-06 22:48:49,983 BAD EPOCHS (no improvement): 4\n",
            "2020-12-06 22:48:49,984 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:49:33,466 epoch 28 - iter 69/698 - loss 0.44617262 - samples/sec: 50.79 - lr: 0.050000\n",
            "2020-12-06 22:50:16,203 epoch 28 - iter 138/698 - loss 0.40762057 - samples/sec: 51.67 - lr: 0.050000\n",
            "2020-12-06 22:50:57,591 epoch 28 - iter 207/698 - loss 0.42205256 - samples/sec: 53.36 - lr: 0.050000\n",
            "2020-12-06 22:51:36,332 epoch 28 - iter 276/698 - loss 0.42022077 - samples/sec: 57.01 - lr: 0.050000\n",
            "2020-12-06 22:52:18,582 epoch 28 - iter 345/698 - loss 0.41613546 - samples/sec: 52.27 - lr: 0.050000\n",
            "2020-12-06 22:52:58,988 epoch 28 - iter 414/698 - loss 0.41749069 - samples/sec: 54.65 - lr: 0.050000\n",
            "2020-12-06 22:53:39,406 epoch 28 - iter 483/698 - loss 0.44006586 - samples/sec: 54.64 - lr: 0.050000\n",
            "2020-12-06 22:54:21,930 epoch 28 - iter 552/698 - loss 0.43307659 - samples/sec: 51.93 - lr: 0.050000\n",
            "2020-12-06 22:55:01,545 epoch 28 - iter 621/698 - loss 0.43508029 - samples/sec: 55.75 - lr: 0.050000\n",
            "2020-12-06 22:55:40,775 epoch 28 - iter 690/698 - loss 0.42446232 - samples/sec: 56.30 - lr: 0.050000\n",
            "2020-12-06 22:55:45,782 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:55:45,784 EPOCH 28 done: loss 0.4236 - lr 0.0500000\n",
            "2020-12-06 22:56:02,482 DEV : loss 0.8467469215393066 - score 0.918\n",
            "2020-12-06 22:56:02,675 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 22:56:02,676 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 22:56:40,745 epoch 29 - iter 69/698 - loss 0.32402990 - samples/sec: 58.01 - lr: 0.050000\n",
            "2020-12-06 22:57:21,641 epoch 29 - iter 138/698 - loss 0.36837416 - samples/sec: 54.00 - lr: 0.050000\n",
            "2020-12-06 22:58:03,305 epoch 29 - iter 207/698 - loss 0.37300071 - samples/sec: 53.00 - lr: 0.050000\n",
            "2020-12-06 22:58:44,310 epoch 29 - iter 276/698 - loss 0.36641214 - samples/sec: 53.86 - lr: 0.050000\n",
            "2020-12-06 22:59:26,089 epoch 29 - iter 345/698 - loss 0.40410390 - samples/sec: 52.86 - lr: 0.050000\n",
            "2020-12-06 23:00:10,233 epoch 29 - iter 414/698 - loss 0.40965192 - samples/sec: 50.03 - lr: 0.050000\n",
            "2020-12-06 23:00:49,654 epoch 29 - iter 483/698 - loss 0.40965592 - samples/sec: 56.02 - lr: 0.050000\n",
            "2020-12-06 23:01:28,753 epoch 29 - iter 552/698 - loss 0.40370924 - samples/sec: 56.48 - lr: 0.050000\n",
            "2020-12-06 23:02:08,127 epoch 29 - iter 621/698 - loss 0.40367388 - samples/sec: 56.09 - lr: 0.050000\n",
            "2020-12-06 23:02:52,012 epoch 29 - iter 690/698 - loss 0.40514098 - samples/sec: 50.32 - lr: 0.050000\n",
            "2020-12-06 23:02:56,417 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:02:56,418 EPOCH 29 done: loss 0.4040 - lr 0.0500000\n",
            "2020-12-06 23:03:13,509 DEV : loss 0.8250178098678589 - score 0.9195\n",
            "2020-12-06 23:03:13,706 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 23:03:20,838 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:04:01,000 epoch 30 - iter 69/698 - loss 0.35988188 - samples/sec: 54.99 - lr: 0.050000\n",
            "2020-12-06 23:04:42,249 epoch 30 - iter 138/698 - loss 0.43733268 - samples/sec: 53.54 - lr: 0.050000\n",
            "2020-12-06 23:05:23,246 epoch 30 - iter 207/698 - loss 0.41363621 - samples/sec: 53.87 - lr: 0.050000\n",
            "2020-12-06 23:06:02,676 epoch 30 - iter 276/698 - loss 0.40008811 - samples/sec: 56.01 - lr: 0.050000\n",
            "2020-12-06 23:06:42,893 epoch 30 - iter 345/698 - loss 0.39732215 - samples/sec: 54.91 - lr: 0.050000\n",
            "2020-12-06 23:07:24,972 epoch 30 - iter 414/698 - loss 0.39979928 - samples/sec: 52.48 - lr: 0.050000\n",
            "2020-12-06 23:08:05,259 epoch 30 - iter 483/698 - loss 0.39358592 - samples/sec: 54.82 - lr: 0.050000\n",
            "2020-12-06 23:08:46,857 epoch 30 - iter 552/698 - loss 0.39351528 - samples/sec: 53.09 - lr: 0.050000\n",
            "2020-12-06 23:09:27,177 epoch 30 - iter 621/698 - loss 0.39111438 - samples/sec: 54.77 - lr: 0.050000\n",
            "2020-12-06 23:10:09,930 epoch 30 - iter 690/698 - loss 0.39542272 - samples/sec: 51.66 - lr: 0.050000\n",
            "2020-12-06 23:10:14,570 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:10:14,571 EPOCH 30 done: loss 0.3947 - lr 0.0500000\n",
            "2020-12-06 23:10:31,860 DEV : loss 0.8164955973625183 - score 0.9206\n",
            "2020-12-06 23:10:32,058 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 23:10:39,224 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:11:23,075 epoch 31 - iter 69/698 - loss 0.54174190 - samples/sec: 50.37 - lr: 0.050000\n",
            "2020-12-06 23:12:05,110 epoch 31 - iter 138/698 - loss 0.46486471 - samples/sec: 52.54 - lr: 0.050000\n",
            "2020-12-06 23:12:44,081 epoch 31 - iter 207/698 - loss 0.41825030 - samples/sec: 56.67 - lr: 0.050000\n",
            "2020-12-06 23:13:23,567 epoch 31 - iter 276/698 - loss 0.40480787 - samples/sec: 55.93 - lr: 0.050000\n",
            "2020-12-06 23:14:03,316 epoch 31 - iter 345/698 - loss 0.40443761 - samples/sec: 55.56 - lr: 0.050000\n",
            "2020-12-06 23:14:45,634 epoch 31 - iter 414/698 - loss 0.40295113 - samples/sec: 52.19 - lr: 0.050000\n",
            "2020-12-06 23:15:24,893 epoch 31 - iter 483/698 - loss 0.39421001 - samples/sec: 56.26 - lr: 0.050000\n",
            "2020-12-06 23:16:05,476 epoch 31 - iter 552/698 - loss 0.39630044 - samples/sec: 54.42 - lr: 0.050000\n",
            "2020-12-06 23:16:48,715 epoch 31 - iter 621/698 - loss 0.39600945 - samples/sec: 51.07 - lr: 0.050000\n",
            "2020-12-06 23:17:28,925 epoch 31 - iter 690/698 - loss 0.39265521 - samples/sec: 54.92 - lr: 0.050000\n",
            "2020-12-06 23:17:33,857 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:17:33,859 EPOCH 31 done: loss 0.3926 - lr 0.0500000\n",
            "2020-12-06 23:17:51,302 DEV : loss 0.8136110901832581 - score 0.9211\n",
            "2020-12-06 23:17:51,502 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 23:17:58,719 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:18:38,248 epoch 32 - iter 69/698 - loss 0.40132381 - samples/sec: 55.88 - lr: 0.050000\n",
            "2020-12-06 23:19:22,303 epoch 32 - iter 138/698 - loss 0.45920143 - samples/sec: 50.13 - lr: 0.050000\n",
            "2020-12-06 23:20:03,870 epoch 32 - iter 207/698 - loss 0.42982804 - samples/sec: 53.13 - lr: 0.050000\n",
            "2020-12-06 23:20:44,673 epoch 32 - iter 276/698 - loss 0.42149363 - samples/sec: 54.12 - lr: 0.050000\n",
            "2020-12-06 23:21:26,705 epoch 32 - iter 345/698 - loss 0.41000830 - samples/sec: 52.54 - lr: 0.050000\n",
            "2020-12-06 23:22:08,280 epoch 32 - iter 414/698 - loss 0.40596458 - samples/sec: 53.12 - lr: 0.050000\n",
            "2020-12-06 23:22:48,855 epoch 32 - iter 483/698 - loss 0.39504660 - samples/sec: 54.43 - lr: 0.050000\n",
            "2020-12-06 23:23:31,651 epoch 32 - iter 552/698 - loss 0.39659126 - samples/sec: 51.60 - lr: 0.050000\n",
            "2020-12-06 23:24:13,417 epoch 32 - iter 621/698 - loss 0.39232827 - samples/sec: 52.88 - lr: 0.050000\n",
            "2020-12-06 23:24:53,434 epoch 32 - iter 690/698 - loss 0.39290479 - samples/sec: 55.19 - lr: 0.050000\n",
            "2020-12-06 23:24:58,072 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:24:58,073 EPOCH 32 done: loss 0.3912 - lr 0.0500000\n",
            "2020-12-06 23:25:14,905 DEV : loss 0.8096861243247986 - score 0.9212\n",
            "2020-12-06 23:25:15,124 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 23:25:22,458 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:26:02,859 epoch 33 - iter 69/698 - loss 0.34981406 - samples/sec: 54.66 - lr: 0.050000\n",
            "2020-12-06 23:26:44,693 epoch 33 - iter 138/698 - loss 0.39504002 - samples/sec: 52.79 - lr: 0.050000\n",
            "2020-12-06 23:27:25,758 epoch 33 - iter 207/698 - loss 0.38206422 - samples/sec: 53.78 - lr: 0.050000\n",
            "2020-12-06 23:28:05,511 epoch 33 - iter 276/698 - loss 0.37574666 - samples/sec: 55.55 - lr: 0.050000\n",
            "2020-12-06 23:28:48,070 epoch 33 - iter 345/698 - loss 0.37572299 - samples/sec: 51.89 - lr: 0.050000\n",
            "2020-12-06 23:29:31,236 epoch 33 - iter 414/698 - loss 0.37558636 - samples/sec: 51.16 - lr: 0.050000\n",
            "2020-12-06 23:30:10,383 epoch 33 - iter 483/698 - loss 0.37411298 - samples/sec: 56.41 - lr: 0.050000\n",
            "2020-12-06 23:30:49,974 epoch 33 - iter 552/698 - loss 0.37286166 - samples/sec: 55.78 - lr: 0.050000\n",
            "2020-12-06 23:31:30,668 epoch 33 - iter 621/698 - loss 0.38616925 - samples/sec: 54.27 - lr: 0.050000\n",
            "2020-12-06 23:32:11,793 epoch 33 - iter 690/698 - loss 0.38331602 - samples/sec: 53.70 - lr: 0.050000\n",
            "2020-12-06 23:32:16,012 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:32:16,015 EPOCH 33 done: loss 0.3850 - lr 0.0500000\n",
            "2020-12-06 23:32:33,135 DEV : loss 0.7857298851013184 - score 0.9197\n",
            "2020-12-06 23:32:33,332 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 23:32:33,340 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:33:14,187 epoch 34 - iter 69/698 - loss 0.33069038 - samples/sec: 54.07 - lr: 0.050000\n",
            "2020-12-06 23:33:54,218 epoch 34 - iter 138/698 - loss 0.32061932 - samples/sec: 55.17 - lr: 0.050000\n",
            "2020-12-06 23:34:36,418 epoch 34 - iter 207/698 - loss 0.33267135 - samples/sec: 52.33 - lr: 0.050000\n",
            "2020-12-06 23:35:15,601 epoch 34 - iter 276/698 - loss 0.33350870 - samples/sec: 56.37 - lr: 0.050000\n",
            "2020-12-06 23:35:57,741 epoch 34 - iter 345/698 - loss 0.36354119 - samples/sec: 52.40 - lr: 0.050000\n",
            "2020-12-06 23:36:40,313 epoch 34 - iter 414/698 - loss 0.36701912 - samples/sec: 51.87 - lr: 0.050000\n",
            "2020-12-06 23:37:20,906 epoch 34 - iter 483/698 - loss 0.36753198 - samples/sec: 54.40 - lr: 0.050000\n",
            "2020-12-06 23:38:01,271 epoch 34 - iter 552/698 - loss 0.36786716 - samples/sec: 54.71 - lr: 0.050000\n",
            "2020-12-06 23:38:43,450 epoch 34 - iter 621/698 - loss 0.36587605 - samples/sec: 52.36 - lr: 0.050000\n",
            "2020-12-06 23:39:25,097 epoch 34 - iter 690/698 - loss 0.36665200 - samples/sec: 53.03 - lr: 0.050000\n",
            "2020-12-06 23:39:29,028 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:39:29,029 EPOCH 34 done: loss 0.3659 - lr 0.0500000\n",
            "2020-12-06 23:39:45,903 DEV : loss 0.8115979433059692 - score 0.9217\n",
            "2020-12-06 23:39:46,101 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 23:39:53,277 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:40:35,295 epoch 35 - iter 69/698 - loss 0.31742481 - samples/sec: 52.56 - lr: 0.050000\n",
            "2020-12-06 23:41:14,903 epoch 35 - iter 138/698 - loss 0.32891550 - samples/sec: 55.76 - lr: 0.050000\n",
            "2020-12-06 23:41:58,921 epoch 35 - iter 207/698 - loss 0.38945941 - samples/sec: 50.17 - lr: 0.050000\n",
            "2020-12-06 23:42:39,071 epoch 35 - iter 276/698 - loss 0.37847358 - samples/sec: 55.00 - lr: 0.050000\n",
            "2020-12-06 23:43:18,196 epoch 35 - iter 345/698 - loss 0.37044218 - samples/sec: 56.45 - lr: 0.050000\n",
            "2020-12-06 23:43:58,609 epoch 35 - iter 414/698 - loss 0.37153387 - samples/sec: 54.65 - lr: 0.050000\n",
            "2020-12-06 23:44:38,919 epoch 35 - iter 483/698 - loss 0.37228193 - samples/sec: 54.78 - lr: 0.050000\n",
            "2020-12-06 23:45:21,797 epoch 35 - iter 552/698 - loss 0.37627188 - samples/sec: 51.50 - lr: 0.050000\n",
            "2020-12-06 23:46:00,928 epoch 35 - iter 621/698 - loss 0.37381461 - samples/sec: 56.44 - lr: 0.050000\n",
            "2020-12-06 23:46:41,289 epoch 35 - iter 690/698 - loss 0.37093254 - samples/sec: 54.72 - lr: 0.050000\n",
            "2020-12-06 23:46:45,887 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:46:45,888 EPOCH 35 done: loss 0.3717 - lr 0.0500000\n",
            "2020-12-06 23:47:03,053 DEV : loss 0.7891795039176941 - score 0.9205\n",
            "2020-12-06 23:47:03,244 BAD EPOCHS (no improvement): 1\n",
            "2020-12-06 23:47:03,252 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:47:45,983 epoch 36 - iter 69/698 - loss 0.37977588 - samples/sec: 51.68 - lr: 0.050000\n",
            "2020-12-06 23:48:28,169 epoch 36 - iter 138/698 - loss 0.38612337 - samples/sec: 52.35 - lr: 0.050000\n",
            "2020-12-06 23:49:07,727 epoch 36 - iter 207/698 - loss 0.36374272 - samples/sec: 55.83 - lr: 0.050000\n",
            "2020-12-06 23:49:48,408 epoch 36 - iter 276/698 - loss 0.35249638 - samples/sec: 54.29 - lr: 0.050000\n",
            "2020-12-06 23:50:29,997 epoch 36 - iter 345/698 - loss 0.35186401 - samples/sec: 53.10 - lr: 0.050000\n",
            "2020-12-06 23:51:09,283 epoch 36 - iter 414/698 - loss 0.35351975 - samples/sec: 56.21 - lr: 0.050000\n",
            "2020-12-06 23:51:48,325 epoch 36 - iter 483/698 - loss 0.35426748 - samples/sec: 56.57 - lr: 0.050000\n",
            "2020-12-06 23:52:29,887 epoch 36 - iter 552/698 - loss 0.36701698 - samples/sec: 53.13 - lr: 0.050000\n",
            "2020-12-06 23:53:08,279 epoch 36 - iter 621/698 - loss 0.36326193 - samples/sec: 57.52 - lr: 0.050000\n",
            "2020-12-06 23:53:48,469 epoch 36 - iter 690/698 - loss 0.36448652 - samples/sec: 54.95 - lr: 0.050000\n",
            "2020-12-06 23:53:52,641 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:53:52,644 EPOCH 36 done: loss 0.3656 - lr 0.0500000\n",
            "2020-12-06 23:54:09,461 DEV : loss 0.8094637393951416 - score 0.9227\n",
            "2020-12-06 23:54:09,689 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-06 23:54:16,891 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-06 23:54:57,792 epoch 37 - iter 69/698 - loss 0.30717783 - samples/sec: 54.01 - lr: 0.050000\n",
            "2020-12-06 23:55:37,963 epoch 37 - iter 138/698 - loss 0.33427986 - samples/sec: 54.97 - lr: 0.050000\n",
            "2020-12-06 23:56:21,097 epoch 37 - iter 207/698 - loss 0.35104311 - samples/sec: 51.20 - lr: 0.050000\n",
            "2020-12-06 23:57:03,345 epoch 37 - iter 276/698 - loss 0.38451281 - samples/sec: 52.27 - lr: 0.050000\n",
            "2020-12-06 23:57:42,958 epoch 37 - iter 345/698 - loss 0.37628110 - samples/sec: 55.75 - lr: 0.050000\n",
            "2020-12-06 23:58:23,051 epoch 37 - iter 414/698 - loss 0.36259487 - samples/sec: 55.08 - lr: 0.050000\n",
            "2020-12-06 23:59:03,737 epoch 37 - iter 483/698 - loss 0.35756988 - samples/sec: 54.28 - lr: 0.050000\n",
            "2020-12-06 23:59:44,089 epoch 37 - iter 552/698 - loss 0.35872327 - samples/sec: 54.73 - lr: 0.050000\n",
            "2020-12-07 00:00:24,707 epoch 37 - iter 621/698 - loss 0.35867358 - samples/sec: 54.37 - lr: 0.050000\n",
            "2020-12-07 00:01:05,667 epoch 37 - iter 690/698 - loss 0.35735173 - samples/sec: 53.92 - lr: 0.050000\n",
            "2020-12-07 00:01:10,132 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:01:10,133 EPOCH 37 done: loss 0.3564 - lr 0.0500000\n",
            "2020-12-07 00:01:26,755 DEV : loss 0.8054664134979248 - score 0.9231\n",
            "2020-12-07 00:01:26,950 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-07 00:01:34,085 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:02:12,971 epoch 38 - iter 69/698 - loss 0.33130906 - samples/sec: 56.80 - lr: 0.050000\n",
            "2020-12-07 00:02:53,267 epoch 38 - iter 138/698 - loss 0.32752181 - samples/sec: 54.80 - lr: 0.050000\n",
            "2020-12-07 00:03:35,953 epoch 38 - iter 207/698 - loss 0.36640240 - samples/sec: 51.74 - lr: 0.050000\n",
            "2020-12-07 00:04:16,492 epoch 38 - iter 276/698 - loss 0.35719324 - samples/sec: 54.48 - lr: 0.050000\n",
            "2020-12-07 00:04:58,670 epoch 38 - iter 345/698 - loss 0.35214306 - samples/sec: 52.36 - lr: 0.050000\n",
            "2020-12-07 00:05:36,636 epoch 38 - iter 414/698 - loss 0.35210767 - samples/sec: 58.17 - lr: 0.050000\n",
            "2020-12-07 00:06:15,937 epoch 38 - iter 483/698 - loss 0.35173940 - samples/sec: 56.20 - lr: 0.050000\n",
            "2020-12-07 00:06:56,829 epoch 38 - iter 552/698 - loss 0.34826709 - samples/sec: 54.00 - lr: 0.050000\n",
            "2020-12-07 00:07:39,211 epoch 38 - iter 621/698 - loss 0.35441989 - samples/sec: 52.11 - lr: 0.050000\n",
            "2020-12-07 00:08:20,173 epoch 38 - iter 690/698 - loss 0.35857849 - samples/sec: 53.92 - lr: 0.050000\n",
            "2020-12-07 00:08:24,969 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:08:24,970 EPOCH 38 done: loss 0.3592 - lr 0.0500000\n",
            "2020-12-07 00:08:41,934 DEV : loss 0.8051316142082214 - score 0.924\n",
            "2020-12-07 00:08:42,141 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-07 00:08:49,370 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:09:31,185 epoch 39 - iter 69/698 - loss 0.37276732 - samples/sec: 52.82 - lr: 0.050000\n",
            "2020-12-07 00:10:15,328 epoch 39 - iter 138/698 - loss 0.38590995 - samples/sec: 50.03 - lr: 0.050000\n",
            "2020-12-07 00:10:57,951 epoch 39 - iter 207/698 - loss 0.38330030 - samples/sec: 51.81 - lr: 0.050000\n",
            "2020-12-07 00:11:36,185 epoch 39 - iter 276/698 - loss 0.36008856 - samples/sec: 57.76 - lr: 0.050000\n",
            "2020-12-07 00:12:17,318 epoch 39 - iter 345/698 - loss 0.37624826 - samples/sec: 53.69 - lr: 0.050000\n",
            "2020-12-07 00:12:56,722 epoch 39 - iter 414/698 - loss 0.36801700 - samples/sec: 56.05 - lr: 0.050000\n",
            "2020-12-07 00:13:39,379 epoch 39 - iter 483/698 - loss 0.35976834 - samples/sec: 51.77 - lr: 0.050000\n",
            "2020-12-07 00:14:19,127 epoch 39 - iter 552/698 - loss 0.35629550 - samples/sec: 55.56 - lr: 0.050000\n",
            "2020-12-07 00:15:00,938 epoch 39 - iter 621/698 - loss 0.35776100 - samples/sec: 52.82 - lr: 0.050000\n",
            "2020-12-07 00:15:41,806 epoch 39 - iter 690/698 - loss 0.35561620 - samples/sec: 54.04 - lr: 0.050000\n",
            "2020-12-07 00:15:45,482 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:15:45,485 EPOCH 39 done: loss 0.3553 - lr 0.0500000\n",
            "2020-12-07 00:16:02,337 DEV : loss 0.8035460114479065 - score 0.9208\n",
            "2020-12-07 00:16:02,532 BAD EPOCHS (no improvement): 1\n",
            "2020-12-07 00:16:02,534 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:16:43,027 epoch 40 - iter 69/698 - loss 0.33439406 - samples/sec: 54.54 - lr: 0.050000\n",
            "2020-12-07 00:17:27,606 epoch 40 - iter 138/698 - loss 0.43258177 - samples/sec: 49.54 - lr: 0.050000\n",
            "2020-12-07 00:18:07,888 epoch 40 - iter 207/698 - loss 0.38945914 - samples/sec: 54.82 - lr: 0.050000\n",
            "2020-12-07 00:18:49,486 epoch 40 - iter 276/698 - loss 0.38099965 - samples/sec: 53.09 - lr: 0.050000\n",
            "2020-12-07 00:19:28,964 epoch 40 - iter 345/698 - loss 0.36431149 - samples/sec: 55.94 - lr: 0.050000\n",
            "2020-12-07 00:20:08,472 epoch 40 - iter 414/698 - loss 0.35068843 - samples/sec: 55.90 - lr: 0.050000\n",
            "2020-12-07 00:20:47,728 epoch 40 - iter 483/698 - loss 0.35306391 - samples/sec: 56.26 - lr: 0.050000\n",
            "2020-12-07 00:21:31,509 epoch 40 - iter 552/698 - loss 0.35326421 - samples/sec: 50.44 - lr: 0.050000\n",
            "2020-12-07 00:22:11,091 epoch 40 - iter 621/698 - loss 0.34729608 - samples/sec: 55.79 - lr: 0.050000\n",
            "2020-12-07 00:22:52,527 epoch 40 - iter 690/698 - loss 0.34619496 - samples/sec: 53.30 - lr: 0.050000\n",
            "2020-12-07 00:22:58,037 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:22:58,040 EPOCH 40 done: loss 0.3465 - lr 0.0500000\n",
            "2020-12-07 00:23:15,210 DEV : loss 0.7893709540367126 - score 0.9235\n",
            "2020-12-07 00:23:15,413 BAD EPOCHS (no improvement): 2\n",
            "2020-12-07 00:23:15,415 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:23:57,215 epoch 41 - iter 69/698 - loss 0.33232732 - samples/sec: 52.83 - lr: 0.050000\n",
            "2020-12-07 00:24:39,912 epoch 41 - iter 138/698 - loss 0.35863307 - samples/sec: 51.72 - lr: 0.050000\n",
            "2020-12-07 00:25:21,567 epoch 41 - iter 207/698 - loss 0.35464977 - samples/sec: 53.02 - lr: 0.050000\n",
            "2020-12-07 00:26:02,116 epoch 41 - iter 276/698 - loss 0.34720038 - samples/sec: 54.46 - lr: 0.050000\n",
            "2020-12-07 00:26:41,771 epoch 41 - iter 345/698 - loss 0.33922095 - samples/sec: 55.69 - lr: 0.050000\n",
            "2020-12-07 00:27:23,081 epoch 41 - iter 414/698 - loss 0.33502170 - samples/sec: 53.46 - lr: 0.050000\n",
            "2020-12-07 00:28:08,442 epoch 41 - iter 483/698 - loss 0.35427726 - samples/sec: 48.68 - lr: 0.050000\n",
            "2020-12-07 00:28:50,306 epoch 41 - iter 552/698 - loss 0.34766061 - samples/sec: 52.75 - lr: 0.050000\n",
            "2020-12-07 00:29:30,924 epoch 41 - iter 621/698 - loss 0.34960307 - samples/sec: 54.37 - lr: 0.050000\n",
            "2020-12-07 00:30:09,913 epoch 41 - iter 690/698 - loss 0.34773092 - samples/sec: 56.64 - lr: 0.050000\n",
            "2020-12-07 00:30:14,303 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:30:14,304 EPOCH 41 done: loss 0.3480 - lr 0.0500000\n",
            "2020-12-07 00:30:31,688 DEV : loss 0.770479142665863 - score 0.9239\n",
            "2020-12-07 00:30:31,884 BAD EPOCHS (no improvement): 3\n",
            "2020-12-07 00:30:31,886 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:31:13,031 epoch 42 - iter 69/698 - loss 0.28340991 - samples/sec: 53.67 - lr: 0.050000\n",
            "2020-12-07 00:31:54,471 epoch 42 - iter 138/698 - loss 0.29947079 - samples/sec: 53.29 - lr: 0.050000\n",
            "2020-12-07 00:32:37,695 epoch 42 - iter 207/698 - loss 0.31006991 - samples/sec: 51.09 - lr: 0.050000\n",
            "2020-12-07 00:33:17,429 epoch 42 - iter 276/698 - loss 0.30708298 - samples/sec: 55.58 - lr: 0.050000\n",
            "2020-12-07 00:33:59,131 epoch 42 - iter 345/698 - loss 0.31282582 - samples/sec: 52.96 - lr: 0.050000\n",
            "2020-12-07 00:34:39,884 epoch 42 - iter 414/698 - loss 0.31972671 - samples/sec: 54.19 - lr: 0.050000\n",
            "2020-12-07 00:35:22,257 epoch 42 - iter 483/698 - loss 0.31534357 - samples/sec: 52.12 - lr: 0.050000\n",
            "2020-12-07 00:36:05,136 epoch 42 - iter 552/698 - loss 0.32054026 - samples/sec: 51.50 - lr: 0.050000\n",
            "2020-12-07 00:36:51,112 epoch 42 - iter 621/698 - loss 0.33954509 - samples/sec: 48.03 - lr: 0.050000\n",
            "2020-12-07 00:37:34,591 epoch 42 - iter 690/698 - loss 0.34140157 - samples/sec: 50.79 - lr: 0.050000\n",
            "2020-12-07 00:37:39,679 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:37:39,680 EPOCH 42 done: loss 0.3418 - lr 0.0500000\n",
            "2020-12-07 00:37:56,988 DEV : loss 0.7498860359191895 - score 0.9245\n",
            "2020-12-07 00:37:57,189 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-07 00:38:04,418 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-07 00:38:44,212 epoch 43 - iter 69/698 - loss 0.32859091 - samples/sec: 55.50 - lr: 0.050000\n",
            "2020-12-07 00:39:26,410 epoch 43 - iter 138/698 - loss 0.30441069 - samples/sec: 52.33 - lr: 0.050000\n",
            "2020-12-07 00:40:11,533 epoch 43 - iter 207/698 - loss 0.34422436 - samples/sec: 48.94 - lr: 0.050000\n",
            "2020-12-07 00:40:54,861 epoch 43 - iter 276/698 - loss 0.34016642 - samples/sec: 50.97 - lr: 0.050000\n",
            "2020-12-07 00:41:35,827 epoch 43 - iter 345/698 - loss 0.33363068 - samples/sec: 53.91 - lr: 0.050000\n",
            "2020-12-07 00:42:20,014 epoch 43 - iter 414/698 - loss 0.32471309 - samples/sec: 49.98 - lr: 0.050000\n",
            "2020-12-07 00:43:05,098 epoch 43 - iter 483/698 - loss 0.32216938 - samples/sec: 48.98 - lr: 0.050000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8baGrFMXYd0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}